#BSUB -J finetune_classifier_GPU
#BSUB -P acc_EHR_ML 
#BSUB -q gpu
#BSUB -R span[hosts=1]
#BSUB -n 3
#BSUB -R affinity[core(16)]
#BSUB -W 100:00
#BSUB -R rusage[mem=200000]
#BSUB -gpu num=3
#BSUB -R h100nvl
#BSUB -oo /sc/arion/projects/ECHO_ML/gulamf01/multimodal_LLM/src/1_pretrain-model/1.3.0_finetune-classifier/logs/%J.stdout 
#BSUB -eo /sc/arion/projects/ECHO_ML/gulamf01/multimodal_LLM/src/1_pretrain-model/1.3.0_finetune-classifier/logs/%J.stderr 
#BSUB -L /bin/bash 

ml purge
module load anaconda3/2024.06
ml proxies
# ml cuda/12.1.1
source activate vjepa
export PATH=$PATH:$PYTHONPATH
export PATH=$PATH:/sc/arion/projects/ECHO_ML/jiangj07/vjepa/envs/vjepa/bin

# 
#echo $PATH
#echo $PYTHONPATH

# pip3 install pydicom


# Run script
# export CUDA_VISIBLE_DEVICES=0,1,6
# # export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True 
cd /sc/arion/projects/ECHO_ML/gulamf01/multimodal_LLM/src/1_pretrain-model/1.3.0_finetune-classifier

# Run test dataloaders. 
# torchrun --standalone --nproc_per_node=3 train-loop-gpu-huge.py --config_path /sc/arion/projects/ECHO_ML/gulamf01/multimodal_LLM/src/1_pretrain-model/1.2.3_train-loop-gpu-huge/config.yaml
# torchrun --standalone --nproc_per_node=3 train-loop-gpu-torchload.py --config_path /sc/arion/projects/ECHO_ML/gulamf01/multimodal_LLM/src/1_pretrain-model/1.2.3_train-loop-gpu-huge/config.yaml
python finetune-classifier_split.py --config_path /sc/arion/projects/ECHO_ML/gulamf01/multimodal_LLM/src/1_pretrain-model/1.3.0_finetune-classifier/config.yaml
